{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to write executable - trying to use .deleteme logic\n",
      "ERROR: Could not install packages due to an OSError: [WinError 2] A rendszer nem találja a megadott fájlt: 'C:\\\\Python311\\\\Scripts\\\\kaggle.exe' -> 'C:\\\\Python311\\\\Scripts\\\\kaggle.exe.deleteme'\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download api token from: https://www.kaggle.com/settings -> and upload here:\n",
    "# from google.colab import files\n",
    "\n",
    "# files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The syntax of the command is incorrect.\n",
      "'cp' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'chmod' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'kaggle' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!mkdir ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "!kaggle datasets download -d nguyentuannguyen/optiver-trading-at-the-close\n",
    "!unzip optiver-trading-at-the-close.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/optiver-trading-at-the-close/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/content/optiver-trading-at-the-close/train.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m train_dataset\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/optiver-trading-at-the-close/train.csv'"
     ]
    }
   ],
   "source": [
    "train_dataset = pd.read_csv('/content/optiver-trading-at-the-close/train.csv')\n",
    "train_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5237980, 17)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = pd.read_csv('content/optiver-trading-at-the-close/train.csv')\n",
    "train_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection and engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stock_id                     int64\n",
       "date_id                      int64\n",
       "seconds_in_bucket            int64\n",
       "imbalance_size             float32\n",
       "imbalance_buy_sell_flag      int64\n",
       "reference_price            float32\n",
       "matched_size               float32\n",
       "far_price                  float32\n",
       "near_price                 float32\n",
       "bid_price                  float32\n",
       "bid_size                   float32\n",
       "ask_price                  float32\n",
       "ask_size                   float32\n",
       "wap                        float32\n",
       "target                     float32\n",
       "time_id                      int64\n",
       "row_id                      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of columns to convert to float32\n",
    "columns_to_convert = ['reference_price', 'matched_size', 'far_price', 'near_price',\n",
    "                      'bid_price', 'bid_size', 'ask_price', 'ask_size',\n",
    "                      'wap', 'target', 'imbalance_size']\n",
    "\n",
    "# Convert the columns to float32\n",
    "train_dataset[columns_to_convert] = train_dataset[columns_to_convert].astype('float32')\n",
    "train_dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "# Applying Quantile Transformation to follow a normal distribution\n",
    "\n",
    "quantile_transformer = QuantileTransformer(output_distribution='normal', random_state=0)\n",
    "train_dataset['Quantile_imbalance_size'] = quantile_transformer.fit_transform(train_dataset['imbalance_size'].values.reshape(-1, 1)).flatten()\n",
    "train_dataset['Quantile_far_price'] = quantile_transformer.fit_transform(train_dataset['far_price'].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# bid_size\n",
    "train_dataset['Quantile_bid_size'] = quantile_transformer.fit_transform(train_dataset['bid_size'].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# ask_size\n",
    "train_dataset['Quantile_ask_size'] = quantile_transformer.fit_transform(train_dataset['ask_size'].values.reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original features\n",
    "features = ['imbalance_size', 'far_price', 'bid_size', 'ask_size']\n",
    "\n",
    "# drop features\n",
    "train_dataset = train_dataset.drop(features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique</th>\n",
       "      <th>cardinality</th>\n",
       "      <th>with_null</th>\n",
       "      <th>null_pct</th>\n",
       "      <th>dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>stock_id</th>\n",
       "      <td>False</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_id</th>\n",
       "      <td>False</td>\n",
       "      <td>481</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <td>False</td>\n",
       "      <td>55</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reference_price</th>\n",
       "      <td>False</td>\n",
       "      <td>28741</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matched_size</th>\n",
       "      <td>False</td>\n",
       "      <td>2875627</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>near_price</th>\n",
       "      <td>False</td>\n",
       "      <td>84625</td>\n",
       "      <td>True</td>\n",
       "      <td>54.55</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bid_price</th>\n",
       "      <td>False</td>\n",
       "      <td>28313</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ask_price</th>\n",
       "      <td>False</td>\n",
       "      <td>28266</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wap</th>\n",
       "      <td>False</td>\n",
       "      <td>31506</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>False</td>\n",
       "      <td>15934</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_id</th>\n",
       "      <td>False</td>\n",
       "      <td>26455</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_id</th>\n",
       "      <td>True</td>\n",
       "      <td>5237980</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quantile_imbalance_size</th>\n",
       "      <td>False</td>\n",
       "      <td>2682391</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quantile_far_price</th>\n",
       "      <td>False</td>\n",
       "      <td>95275</td>\n",
       "      <td>True</td>\n",
       "      <td>55.26</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quantile_bid_size</th>\n",
       "      <td>False</td>\n",
       "      <td>2485546</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quantile_ask_size</th>\n",
       "      <td>False</td>\n",
       "      <td>2512524</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         unique  cardinality  with_null  null_pct    dtype\n",
       "stock_id                  False          200      False      0.00    int64\n",
       "date_id                   False          481      False      0.00    int64\n",
       "seconds_in_bucket         False           55      False      0.00    int64\n",
       "imbalance_buy_sell_flag   False            3      False      0.00    int64\n",
       "reference_price           False        28741       True      0.00  float32\n",
       "matched_size              False      2875627       True      0.00  float32\n",
       "near_price                False        84625       True     54.55  float32\n",
       "bid_price                 False        28313       True      0.00  float32\n",
       "ask_price                 False        28266       True      0.00  float32\n",
       "wap                       False        31506       True      0.00  float32\n",
       "target                    False        15934       True      0.00  float32\n",
       "time_id                   False        26455      False      0.00    int64\n",
       "row_id                     True      5237980      False      0.00   object\n",
       "Quantile_imbalance_size   False      2682391       True      0.00  float32\n",
       "Quantile_far_price        False        95275       True     55.26  float32\n",
       "Quantile_bid_size         False      2485546      False      0.00  float32\n",
       "Quantile_ask_size         False      2512524      False      0.00  float32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def inspect_columns(df):\n",
    "    result = pd.DataFrame({\n",
    "        'unique': df.nunique() == len(df),\n",
    "        'cardinality': df.nunique(),\n",
    "        'with_null': df.isna().any(),\n",
    "#         'null_num': df.isnull().sum(),\n",
    "        'null_pct': round((df.isnull().sum() / len(df)) * 100, 2),\n",
    "#         '1st_row': df.iloc[0],\n",
    "#         'last_row': df.iloc[-1],\n",
    "        'dtype': df.dtypes\n",
    "    })\n",
    "    return result\n",
    "\n",
    "inspect_columns(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset['volume'] = train_dataset['Quantile_ask_size'] + train_dataset['Quantile_bid_size']\n",
    "train_dataset['volume_norm'] = (train_dataset['volume'] - train_dataset['volume'].mean()) / train_dataset['volume'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5237760, 19)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = train_dataset.copy()\n",
    "\n",
    "def drop_missing_values(df):\n",
    "    # drop the missing values of wap\n",
    "    df = df.dropna(subset=['wap'])\n",
    "    return df\n",
    "# drop the missing values of wap\n",
    "df_train = drop_missing_values(df_train)\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### keep only the features selected in \"trading_at_the_close_visualisation\"\n",
    " ['stock_id' 'date_id' 'seconds_in_bucket' 'imbalance_size'\n",
    " 'reference_price' 'matched_size' 'far_price' 'near_price' 'bid_price'\n",
    " 'bid_size' 'ask_price' 'ask_size' 'wap' 'row_id' 'date_id_week'\n",
    " 'date_id_seconds' 'total_volume' 'near_far_ratio' 'near_far_imbalance'\n",
    " 'ask_mat_ratio' 'bid_mat_ratio' 'ask_ref_ratio'\n",
    " 'imbalance_continuous_ratio' 'ask_wap_diff' 'all_prices_skew'\n",
    " 'all_sizes_skew' 'all_prices_kurt' 'all_sizes_kurt'\n",
    " 'imbalance_buy_sell_flag_cumsum' 'imbalance_buy_sell_flag_0'\n",
    " 'imbalance_buy_sell_flag_1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.56 s\n",
      "Wall time: 10.7 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>ask_price</th>\n",
       "      <th>wap</th>\n",
       "      <th>...</th>\n",
       "      <th>ask_wap_diff</th>\n",
       "      <th>imbalance_buy_sell_flag_cumsum</th>\n",
       "      <th>all_prices_mean</th>\n",
       "      <th>all_sizes_mean</th>\n",
       "      <th>all_prices_std</th>\n",
       "      <th>all_sizes_std</th>\n",
       "      <th>all_prices_skew</th>\n",
       "      <th>all_sizes_skew</th>\n",
       "      <th>all_prices_kurt</th>\n",
       "      <th>all_sizes_kurt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5237975</th>\n",
       "      <td>195</td>\n",
       "      <td>480</td>\n",
       "      <td>540</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000317</td>\n",
       "      <td>28280362.0</td>\n",
       "      <td>0.999734</td>\n",
       "      <td>1.000317</td>\n",
       "      <td>1.000434</td>\n",
       "      <td>1.000328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>-54</td>\n",
       "      <td>0.830386</td>\n",
       "      <td>7070091.00</td>\n",
       "      <td>0.416020</td>\n",
       "      <td>14140180.0</td>\n",
       "      <td>-2.449488</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.999992</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237976</th>\n",
       "      <td>196</td>\n",
       "      <td>480</td>\n",
       "      <td>540</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000643</td>\n",
       "      <td>9187699.0</td>\n",
       "      <td>1.000386</td>\n",
       "      <td>1.000643</td>\n",
       "      <td>1.000900</td>\n",
       "      <td>1.000819</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>-55</td>\n",
       "      <td>0.847850</td>\n",
       "      <td>2296925.50</td>\n",
       "      <td>0.374351</td>\n",
       "      <td>4593849.0</td>\n",
       "      <td>-2.449489</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.999995</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237977</th>\n",
       "      <td>197</td>\n",
       "      <td>480</td>\n",
       "      <td>540</td>\n",
       "      <td>0</td>\n",
       "      <td>0.995789</td>\n",
       "      <td>12725436.0</td>\n",
       "      <td>0.995789</td>\n",
       "      <td>0.995789</td>\n",
       "      <td>0.995883</td>\n",
       "      <td>0.995797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>-54</td>\n",
       "      <td>0.705909</td>\n",
       "      <td>3181358.25</td>\n",
       "      <td>0.710108</td>\n",
       "      <td>6362718.5</td>\n",
       "      <td>-2.449490</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237978</th>\n",
       "      <td>198</td>\n",
       "      <td>480</td>\n",
       "      <td>540</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>94773272.0</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>0.998970</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>0.999008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>28</td>\n",
       "      <td>0.809469</td>\n",
       "      <td>23693318.00</td>\n",
       "      <td>0.464552</td>\n",
       "      <td>47386636.0</td>\n",
       "      <td>-2.449490</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.999999</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237979</th>\n",
       "      <td>199</td>\n",
       "      <td>480</td>\n",
       "      <td>540</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.002129</td>\n",
       "      <td>24073678.0</td>\n",
       "      <td>1.001494</td>\n",
       "      <td>1.002129</td>\n",
       "      <td>1.002447</td>\n",
       "      <td>1.002274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>-35</td>\n",
       "      <td>0.882249</td>\n",
       "      <td>6018420.50</td>\n",
       "      <td>0.293562</td>\n",
       "      <td>12036838.0</td>\n",
       "      <td>-2.449483</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.999975</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         stock_id  date_id  seconds_in_bucket  imbalance_buy_sell_flag  \\\n",
       "5237975       195      480                540                       -1   \n",
       "5237976       196      480                540                       -1   \n",
       "5237977       197      480                540                        0   \n",
       "5237978       198      480                540                        1   \n",
       "5237979       199      480                540                       -1   \n",
       "\n",
       "         reference_price  matched_size  near_price  bid_price  ask_price  \\\n",
       "5237975         1.000317    28280362.0    0.999734   1.000317   1.000434   \n",
       "5237976         1.000643     9187699.0    1.000386   1.000643   1.000900   \n",
       "5237977         0.995789    12725436.0    0.995789   0.995789   0.995883   \n",
       "5237978         0.999210    94773272.0    0.999210   0.998970   0.999210   \n",
       "5237979         1.002129    24073678.0    1.001494   1.002129   1.002447   \n",
       "\n",
       "              wap  ...  ask_wap_diff  imbalance_buy_sell_flag_cumsum  \\\n",
       "5237975  1.000328  ...      0.000106                             -54   \n",
       "5237976  1.000819  ...      0.000081                             -55   \n",
       "5237977  0.995797  ...      0.000086                             -54   \n",
       "5237978  0.999008  ...      0.000202                              28   \n",
       "5237979  1.002274  ...      0.000173                             -35   \n",
       "\n",
       "        all_prices_mean  all_sizes_mean  all_prices_std  all_sizes_std  \\\n",
       "5237975        0.830386      7070091.00        0.416020     14140180.0   \n",
       "5237976        0.847850      2296925.50        0.374351      4593849.0   \n",
       "5237977        0.705909      3181358.25        0.710108      6362718.5   \n",
       "5237978        0.809469     23693318.00        0.464552     47386636.0   \n",
       "5237979        0.882249      6018420.50        0.293562     12036838.0   \n",
       "\n",
       "         all_prices_skew  all_sizes_skew  all_prices_kurt  all_sizes_kurt  \n",
       "5237975        -2.449488             2.0         5.999992             4.0  \n",
       "5237976        -2.449489             2.0         5.999995             4.0  \n",
       "5237977        -2.449490             2.0         6.000000             4.0  \n",
       "5237978        -2.449490             2.0         5.999999             4.0  \n",
       "5237979        -2.449483             2.0         5.999975             4.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def calc_feature_single_stock(df):\n",
    "    # Feature of each stock at different time point\n",
    "    # date_id\n",
    "    df[\"date_id_week\"] = df[\"date_id\"] % 5  # Day of the week\n",
    "    df[\"date_id_seconds\"] = df[\"seconds_in_bucket\"] % 60  # Seconds\n",
    "   \n",
    "    \n",
    "    # ask bid \n",
    "    df['spread'] = df['ask_price'] - df['bid_price']\n",
    "   \n",
    "    df['mid_price'] = (df['bid_price'] + df['ask_price'])/2\n",
    "    # product of imbalance size and bid-ask spread\n",
    "    df[\"price_pressure\"] = df[\"Quantile_imbalance_size\"] * (df[\"spread\"])\n",
    "    \n",
    "    # near_price far_price\n",
    "    df['near_far_ratio'] = df['near_price'] / df['Quantile_far_price']\n",
    "    df['near_far_imbalance'] = (df['Quantile_far_price'] - df['near_price']) / (df['Quantile_far_price'] + df['near_price'])\n",
    "   \n",
    "    \n",
    "    #The ratio between ask/bid and matched sizes provides insights into market liquidity and order flow:\n",
    "    # A high ask-to-matched ratio suggests that there are more sellers than buyers at a given price level, \n",
    "    # potentially indicating resistance to upward price movement.\n",
    "    # Conversely, a low ratio implies stronger buying interest and potential support for price increases.\n",
    "    \n",
    "    df['ask_mat_ratio'] = df['Quantile_ask_size']/df['matched_size']\n",
    "    df['bid_mat_ratio'] = df['Quantile_bid_size']/df['matched_size']\n",
    "    \n",
    "    # The ratio between the ask/bid price and the reference price provides insights into market sentiment:\n",
    "    # - Above 1: If the ask/bid price is higher than the reference price, it suggests bullish sentiment. Sellers are demanding a premium.\n",
    "    # - Below 1: If the ask/bid price is lower than the reference price, it indicates bearish sentiment. Buyers are getting a discount.\n",
    "    df['ask_ref_ratio'] = df['ask_price']/df['reference_price']\n",
    "    # imbalance_size matched_size\n",
    "    df['auction_volume'] = df['Quantile_imbalance_size'] + df['matched_size']\n",
    "    # relative imbalance between matched and total size\n",
    "    df[\"imbalance_ratio\"] = (df[\"Quantile_imbalance_size\"] - df[\"matched_size\"]) / (df[\"matched_size\"] + df[\"Quantile_imbalance_size\"])\n",
    "    # cross term \n",
    "    df[\"imbalance_continuous_ratio\"] = df['Quantile_imbalance_size'] / df[\"volume\"]\n",
    "    # the overall level of buying and selling in financial markets\n",
    "    df['market_activity'] = df['Quantile_bid_size'] * df['bid_price'] + df['Quantile_ask_size'] * df['ask_price']\n",
    "    # The difference between the ask/bid price and the WAP can indicate market efficiency.\n",
    "    df['ask_wap_diff'] = df['ask_price'] - df['wap']\n",
    "    # Accumulative features\n",
    "    df['imbalance_buy_sell_flag_cumsum'] =  df.groupby(['stock_id','date_id'])['imbalance_buy_sell_flag'].cumsum()\n",
    "    \n",
    "    # statistical features at different time point\n",
    "    prices = [\"reference_price\", \"Quantile_far_price\", \"near_price\", \"ask_price\", \"bid_price\", \"wap\"]\n",
    "    sizes = [\"matched_size\", \"Quantile_bid_size\", \"Quantile_ask_size\", \"Quantile_imbalance_size\"]\n",
    "    for func in [\"mean\", \"std\", \"skew\", \"kurt\"]:\n",
    "            df[f\"all_prices_{func}\"] = df[prices].agg(func, axis=1)\n",
    "            df[f\"all_sizes_{func}\"] = df[sizes].agg(func, axis=1)\n",
    "            \n",
    "\n",
    "    return df\n",
    "\n",
    "df_train = calc_feature_single_stock(df_train)\n",
    "df_train.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>ask_price</th>\n",
       "      <th>wap</th>\n",
       "      <th>...</th>\n",
       "      <th>imbalance_buy_sell_flag_cumsum</th>\n",
       "      <th>all_prices_mean</th>\n",
       "      <th>all_sizes_mean</th>\n",
       "      <th>all_prices_std</th>\n",
       "      <th>all_sizes_std</th>\n",
       "      <th>all_prices_skew</th>\n",
       "      <th>all_sizes_skew</th>\n",
       "      <th>all_prices_kurt</th>\n",
       "      <th>all_sizes_kurt</th>\n",
       "      <th>vwap_reference_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>13380277.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999913</td>\n",
       "      <td>3.345070e+06</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>6.690138e+06</td>\n",
       "      <td>0.042897</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.589178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>1642214.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>1.000660</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000113</td>\n",
       "      <td>4.105531e+05</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>8.211074e+05</td>\n",
       "      <td>1.897504</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.617163</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.921946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999561</td>\n",
       "      <td>1819368.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>1.000298</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999816</td>\n",
       "      <td>4.548419e+05</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>9.096841e+05</td>\n",
       "      <td>0.311287</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.953897</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-3.830244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000171</td>\n",
       "      <td>18389746.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000096</td>\n",
       "      <td>4.597437e+06</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>9.194873e+06</td>\n",
       "      <td>0.124467</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.279469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>17860614.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>1.000016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999735</td>\n",
       "      <td>4.465153e+06</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>8.930307e+06</td>\n",
       "      <td>-0.156620</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.078881</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-3.027896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id  date_id  seconds_in_bucket  imbalance_buy_sell_flag  \\\n",
       "0         0        0                  0                        1   \n",
       "1         1        0                  0                       -1   \n",
       "2         2        0                  0                       -1   \n",
       "3         3        0                  0                       -1   \n",
       "4         4        0                  0                       -1   \n",
       "\n",
       "   reference_price  matched_size  near_price  bid_price  ask_price  wap  ...  \\\n",
       "0         0.999812   13380277.00         NaN   0.999812   1.000026  1.0  ...   \n",
       "1         0.999896    1642214.25         NaN   0.999896   1.000660  1.0  ...   \n",
       "2         0.999561    1819368.00         NaN   0.999403   1.000298  1.0  ...   \n",
       "3         1.000171   18389746.00         NaN   0.999999   1.000214  1.0  ...   \n",
       "4         0.999532   17860614.00         NaN   0.999394   1.000016  1.0  ...   \n",
       "\n",
       "   imbalance_buy_sell_flag_cumsum  all_prices_mean all_sizes_mean  \\\n",
       "0                               1         0.999913   3.345070e+06   \n",
       "1                              -1         1.000113   4.105531e+05   \n",
       "2                              -1         0.999816   4.548419e+05   \n",
       "3                              -1         1.000096   4.597437e+06   \n",
       "4                              -1         0.999735   4.465153e+06   \n",
       "\n",
       "   all_prices_std  all_sizes_std  all_prices_skew  all_sizes_skew  \\\n",
       "0        0.000117   6.690138e+06         0.042897             2.0   \n",
       "1        0.000368   8.211074e+05         1.897504             2.0   \n",
       "2        0.000409   9.096841e+05         0.311287             2.0   \n",
       "3        0.000113   9.194873e+06         0.124467             2.0   \n",
       "4        0.000320   8.930307e+06        -0.156620             2.0   \n",
       "\n",
       "   all_prices_kurt  all_sizes_kurt  vwap_reference_price  \n",
       "0         0.000000             4.0              9.589178  \n",
       "1         3.617163             4.0             -1.921946  \n",
       "2        -2.953897             4.0             -3.830244  \n",
       "3         0.000000             4.0              9.279469  \n",
       "4        -5.078881             4.0             -3.027896  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def calculate_vwap(df):\n",
    "#     df['vwap_reference_price'] = (df['wap'] * df['reference_price']).cumsum() / df['volume'].cumsum()\n",
    "#     return df\n",
    "# df_train = calculate_vwap(df_train)\n",
    "# df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['rolling_std_reference_price'] = df_train.groupby('stock_id')['reference_price'].transform(lambda x: x.rolling(window=54).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dummy from imbalance_buy_sell_flag and get dummy columns\n",
    "dummy_cols_list = ['imbalance_buy_sell_flag']\n",
    "dummy_names = []\n",
    "\n",
    "for col in dummy_cols_list:\n",
    "    dummy_df = pd.get_dummies(df_train.loc[:, col], prefix=col, drop_first=True)\n",
    "    dummy_names += dummy_df.columns.tolist()\n",
    "    # drop original column\n",
    "    df_train = df_train.drop(col, axis=1)\n",
    "    df_train = pd.concat([df_train, dummy_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# drop these columns\n",
    "df_train = df_train.drop(['all_sizes_std','all_prices_std','all_sizes_mean','market_activity','mid_price'], axis=1)\n",
    "# drop: near_far_mid, auction_volume,all_prices_mean\n",
    "df_train = df_train.drop([ 'auction_volume','all_prices_mean'], axis=1)\n",
    "\n",
    "\n",
    "# drop: time_id\n",
    "df_train = df_train.drop(['time_id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of feature selection (trading_at_the_close_visualisation_1.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['stock_id','target','imbalance_buy_sell_flag_0','imbalance_buy_sell_flag_1', 'rolling_std_reference_price','date_id','seconds_in_bucket', 'ask_ref_ratio', 'Quantile_bid_size', 'Quantile_ask_size',  'ask_wap_diff', 'spread']\n",
    "\n",
    "# keep only the selected features\n",
    "df_train = df_train[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>target</th>\n",
       "      <th>imbalance_buy_sell_flag_0</th>\n",
       "      <th>imbalance_buy_sell_flag_1</th>\n",
       "      <th>rolling_std_reference_price</th>\n",
       "      <th>date_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>ask_ref_ratio</th>\n",
       "      <th>Quantile_bid_size</th>\n",
       "      <th>Quantile_ask_size</th>\n",
       "      <th>ask_wap_diff</th>\n",
       "      <th>spread</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-3.029704</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>0.739395</td>\n",
       "      <td>-0.635130</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-5.519986</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000764</td>\n",
       "      <td>-1.068202</td>\n",
       "      <td>-0.076523</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.000764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-8.389950</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000737</td>\n",
       "      <td>0.391064</td>\n",
       "      <td>-0.133653</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-4.010201</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000043</td>\n",
       "      <td>-1.200443</td>\n",
       "      <td>2.414491</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.000215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-7.349849</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000484</td>\n",
       "      <td>-0.196919</td>\n",
       "      <td>-1.885052</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237975</th>\n",
       "      <td>195</td>\n",
       "      <td>2.310276</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>480</td>\n",
       "      <td>540</td>\n",
       "      <td>1.000117</td>\n",
       "      <td>0.266118</td>\n",
       "      <td>2.022891</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237976</th>\n",
       "      <td>196</td>\n",
       "      <td>-8.220077</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>480</td>\n",
       "      <td>540</td>\n",
       "      <td>1.000257</td>\n",
       "      <td>1.651024</td>\n",
       "      <td>1.058055</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237977</th>\n",
       "      <td>197</td>\n",
       "      <td>1.169443</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001755</td>\n",
       "      <td>480</td>\n",
       "      <td>540</td>\n",
       "      <td>1.000094</td>\n",
       "      <td>-0.185484</td>\n",
       "      <td>1.539343</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237978</th>\n",
       "      <td>198</td>\n",
       "      <td>-1.540184</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>480</td>\n",
       "      <td>540</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.279195</td>\n",
       "      <td>2.784187</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237979</th>\n",
       "      <td>199</td>\n",
       "      <td>-6.530285</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>480</td>\n",
       "      <td>540</td>\n",
       "      <td>1.000317</td>\n",
       "      <td>1.797340</td>\n",
       "      <td>1.965054</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5237760 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         stock_id    target  imbalance_buy_sell_flag_0  \\\n",
       "0               0 -3.029704                      False   \n",
       "1               1 -5.519986                      False   \n",
       "2               2 -8.389950                      False   \n",
       "3               3 -4.010201                      False   \n",
       "4               4 -7.349849                      False   \n",
       "...           ...       ...                        ...   \n",
       "5237975       195  2.310276                      False   \n",
       "5237976       196 -8.220077                      False   \n",
       "5237977       197  1.169443                       True   \n",
       "5237978       198 -1.540184                      False   \n",
       "5237979       199 -6.530285                      False   \n",
       "\n",
       "         imbalance_buy_sell_flag_1  rolling_std_reference_price  date_id  \\\n",
       "0                             True                          NaN        0   \n",
       "1                            False                          NaN        0   \n",
       "2                            False                          NaN        0   \n",
       "3                            False                          NaN        0   \n",
       "4                            False                          NaN        0   \n",
       "...                            ...                          ...      ...   \n",
       "5237975                      False                     0.000270      480   \n",
       "5237976                      False                     0.000518      480   \n",
       "5237977                      False                     0.001755      480   \n",
       "5237978                       True                     0.000460      480   \n",
       "5237979                      False                     0.000485      480   \n",
       "\n",
       "         seconds_in_bucket  ask_ref_ratio  Quantile_bid_size  \\\n",
       "0                        0       1.000214           0.739395   \n",
       "1                        0       1.000764          -1.068202   \n",
       "2                        0       1.000737           0.391064   \n",
       "3                        0       1.000043          -1.200443   \n",
       "4                        0       1.000484          -0.196919   \n",
       "...                    ...            ...                ...   \n",
       "5237975                540       1.000117           0.266118   \n",
       "5237976                540       1.000257           1.651024   \n",
       "5237977                540       1.000094          -0.185484   \n",
       "5237978                540       1.000000           1.279195   \n",
       "5237979                540       1.000317           1.797340   \n",
       "\n",
       "         Quantile_ask_size  ask_wap_diff    spread  \n",
       "0                -0.635130      0.000026  0.000214  \n",
       "1                -0.076523      0.000660  0.000764  \n",
       "2                -0.133653      0.000298  0.000895  \n",
       "3                 2.414491      0.000214  0.000215  \n",
       "4                -1.885052      0.000016  0.000622  \n",
       "...                    ...           ...       ...  \n",
       "5237975           2.022891      0.000106  0.000117  \n",
       "5237976           1.058055      0.000081  0.000257  \n",
       "5237977           1.539343      0.000086  0.000094  \n",
       "5237978           2.784187      0.000202  0.000240  \n",
       "5237979           1.965054      0.000173  0.000318  \n",
       "\n",
       "[5237760 rows x 12 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load from preprocessed file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/optiver-trading-at-the-close/train_preprocess_short.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# load preprocess data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_train \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/optiver-trading-at-the-close/train_preprocess_short.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m selected_features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstock_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimbalance_buy_sell_flag_0\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimbalance_buy_sell_flag_1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrolling_std_matched_size\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseconds_in_bucket\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mask_ref_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuantile_bid_size\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuantile_ask_size\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mask_wap_diff\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspread\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# keep only the selected features\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/optiver-trading-at-the-close/train_preprocess_short.csv'"
     ]
    }
   ],
   "source": [
    "# # load preprocess data\n",
    "# df_train = pd.read_csv('data/optiver-trading-at-the-close/train_preprocess_short.csv')\n",
    "\n",
    "# selected_features = ['stock_id','target','imbalance_buy_sell_flag_0','imbalance_buy_sell_flag_1', 'rolling_std_matched_size','date_id','seconds_in_bucket', 'ask_ref_ratio', 'Quantile_bid_size', 'Quantile_ask_size',  'ask_wap_diff', 'spread']\n",
    "\n",
    "# # keep only the selected features\n",
    "# df_train = df_train[selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "from keras import Sequential\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Input, Dense, LSTM, Dropout\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from xgboost import XGBRegressor, plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "N_LAGS = 55\n",
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 100000\n",
    "EPOCHS = 10\n",
    "PATIENCE = 25\n",
    "DROPOUT = 0.5\n",
    "LEARNING_RATE = 1e-4\n",
    "SPLIT_DAY = 390\n",
    "N_STOCKS = 200\n",
    "N_DATES = 481\n",
    "N_SECONDS = 55\n",
    "RUN_TRAINING = True\n",
    "RUN_FOR_SUBMISSION = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA FORMATTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def windowed_dataset(dataset, shuffle=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(dataset)\n",
    "    dataset = dataset.window(N_LAGS + 1, shift=1, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(N_LAGS + 1))\n",
    "    dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n",
    "    if shuffle:\n",
    "      dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "    dataset = dataset.batch(BATCH_SIZE).prefetch(1)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def build_features(df):\n",
    "\n",
    "    all_stock_ids = range(N_STOCKS)\n",
    "    all_date_ids = df[\"date_id\"].unique()\n",
    "    all_seconds = [i * 10 for i in range(N_SECONDS)]\n",
    "\n",
    "    multi_index = pd.MultiIndex.from_product([all_stock_ids, all_date_ids, all_seconds],\n",
    "                                             names=['stock_id', 'date_id', 'seconds_in_bucket'])\n",
    "    df_full = df.set_index(['stock_id', 'date_id', 'seconds_in_bucket']).reindex(multi_index)\n",
    "    df_full = df_full.fillna(0)\n",
    "    df_full = df_full.reset_index()\n",
    "\n",
    "    df_pivoted = df_full.pivot_table(\n",
    "                values='target',\n",
    "                index=['date_id', 'seconds_in_bucket'],\n",
    "                columns='stock_id')\n",
    "\n",
    "    df_pivoted = df_pivoted.reset_index(drop=True)\n",
    "    df_pivoted.columns.name = None\n",
    "\n",
    "    return df_pivoted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Embedding, GRU, SimpleRNN, Flatten, Conv1D, MaxPooling1D, Conv2D, MaxPooling2D, Bidirectional\n",
    "\n",
    "build_features(df_train)\n",
    "\n",
    "def build_model(dropout=DROPOUT):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(N_LAGS, N_STOCKS)))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(LSTM(25, return_sequences=False))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(N_STOCKS))\n",
    "    model.compile(loss='mae',\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE))\n",
    "    return model\n",
    "\n",
    "def build_model_2(dropout=DROPOUT):\n",
    "    model = Sequential()\n",
    "    #model.add(Input(shape=(N_LAGS, N_STOCKS)))\n",
    "    model.add(Embedding(input_dim=N_STOCKS,output_dim=64))\n",
    "    model.add(GRU(256, return_sequences=True))\n",
    "    model.add(Conv1D(64, 2))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(SimpleRNN(128))\n",
    "    model.add(Conv1D(128, 3))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Dense(64, ))\n",
    "    model.add(LSTM(256, ))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Bidirectional(LSTM(128)))\n",
    "    model.add(Dense(64, ))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, ))\n",
    "    model.add(Dense(N_STOCKS))\n",
    "    model.compile(loss='mae',\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"conv1d_1\" is incompatible with the layer: expected min_ndim=3, found ndim=2. Full shape received: (None, 256)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m valid_dataset \u001b[38;5;241m=\u001b[39m windowed_dataset(valid_features, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#model = build_model()\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model_2\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     21\u001b[0m                   mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     22\u001b[0m                   patience\u001b[38;5;241m=\u001b[39mPATIENCE,\n\u001b[0;32m     23\u001b[0m                   restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     24\u001b[0m                   verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     26\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(train_dataset,\n\u001b[0;32m     27\u001b[0m                     validation_data\u001b[38;5;241m=\u001b[39mvalid_dataset,\n\u001b[0;32m     28\u001b[0m                     epochs\u001b[38;5;241m=\u001b[39mEPOCHS,\n\u001b[0;32m     29\u001b[0m                     batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE,\n\u001b[0;32m     30\u001b[0m                     callbacks\u001b[38;5;241m=\u001b[39m[early_stopping],\n\u001b[0;32m     31\u001b[0m                     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[41], line 21\u001b[0m, in \u001b[0;36mbuild_model_2\u001b[1;34m(dropout)\u001b[0m\n\u001b[0;32m     19\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Embedding(input_dim\u001b[38;5;241m=\u001b[39mN_STOCKS,output_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m))\n\u001b[0;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39madd(GRU(\u001b[38;5;241m256\u001b[39m, ))\n\u001b[1;32m---> 21\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mConv1D\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m model\u001b[38;5;241m.\u001b[39madd(MaxPooling1D(\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m     23\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dropout(\u001b[38;5;241m0.2\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\trackable\\base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 204\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\input_spec.py:253\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    251\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mrank\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m ndim \u001b[38;5;241m<\u001b[39m spec\u001b[38;5;241m.\u001b[39mmin_ndim:\n\u001b[1;32m--> 253\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    254\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    255\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis incompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    256\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected min_ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mmin_ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    257\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    258\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull shape received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    259\u001b[0m         )\n\u001b[0;32m    260\u001b[0m \u001b[38;5;66;03m# Check dtype.\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"conv1d_1\" is incompatible with the layer: expected min_ndim=3, found ndim=2. Full shape received: (None, 256)"
     ]
    }
   ],
   "source": [
    "if RUN_TRAINING:\n",
    "\n",
    "  split = df_train['date_id'] > SPLIT_DAY\n",
    "  df_train_ = df_train[~split]\n",
    "  df_valid = df_train[split]\n",
    "\n",
    "  df_train_features = build_features(df_train_)\n",
    "  df_valid_features = build_features(df_valid)\n",
    "\n",
    "  scaler = StandardScaler()\n",
    "  train_features = scaler.fit_transform(df_train_features)\n",
    "  valid_features = scaler.transform(df_valid_features)\n",
    "\n",
    "  train_dataset = windowed_dataset(train_features)\n",
    "  valid_dataset = windowed_dataset(valid_features, shuffle=False)\n",
    "\n",
    "  #model = build_model()\n",
    "  model = build_model_2()\n",
    "\n",
    "  early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                    mode='min',\n",
    "                    patience=PATIENCE,\n",
    "                    restore_best_weights=True,\n",
    "                    verbose=True)\n",
    "\n",
    "  history = model.fit(train_dataset,\n",
    "                      validation_data=valid_dataset,\n",
    "                      epochs=EPOCHS,\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      callbacks=[early_stopping],\n",
    "                      verbose=True)\n",
    "\n",
    "  ## Evaluate ##\n",
    "  y_pred = model.predict(valid_dataset)\n",
    "\n",
    "  y_pred = scaler.inverse_transform(y_pred)\n",
    "  y_true = df_valid_features[N_LAGS:]\n",
    "\n",
    "  mae = mean_absolute_error(y_true, y_pred)\n",
    "  print(f\"MAE score: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Plots ##\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model train vs validation loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "671/671 [==============================] - 144s 206ms/step - loss: 0.7316 - val_loss: 0.6849\n",
      "Epoch 2/10\n",
      "671/671 [==============================] - 140s 205ms/step - loss: 0.7218 - val_loss: 0.6779\n",
      "Epoch 3/10\n",
      "671/671 [==============================] - 139s 204ms/step - loss: 0.7139 - val_loss: 0.6729\n",
      "Epoch 4/10\n",
      "671/671 [==============================] - 140s 206ms/step - loss: 0.7082 - val_loss: 0.6696\n",
      "Epoch 5/10\n",
      "671/671 [==============================] - 140s 206ms/step - loss: 0.7040 - val_loss: 0.6667\n",
      "Epoch 6/10\n",
      "671/671 [==============================] - 140s 206ms/step - loss: 0.7005 - val_loss: 0.6642\n",
      "Epoch 7/10\n",
      "671/671 [==============================] - 139s 205ms/step - loss: 0.6975 - val_loss: 0.6619\n",
      "Epoch 8/10\n",
      "671/671 [==============================] - 138s 204ms/step - loss: 0.6952 - val_loss: 0.6600\n",
      "Epoch 9/10\n",
      "671/671 [==============================] - 145s 213ms/step - loss: 0.6931 - val_loss: 0.6584\n",
      "Epoch 10/10\n",
      "671/671 [==============================] - 147s 217ms/step - loss: 0.6914 - val_loss: 0.6570\n",
      "153/153 [==============================] - 2s 11ms/step\n",
      "MAE score for hyperparameters {'N_LAGS': 55, 'BATCH_SIZE': 32, 'DROPOUT': 0.3, 'LEARNING_RATE': 0.0001, 'LSTM_UNITS': 25}: 5.834575653076172\n",
      "Epoch 1/10\n",
      "671/671 [==============================] - 197s 287ms/step - loss: 0.7367 - val_loss: 0.6843\n",
      "Epoch 2/10\n",
      "671/671 [==============================] - 193s 286ms/step - loss: 0.7193 - val_loss: 0.6738\n",
      "Epoch 3/10\n",
      "337/671 [==============>...............] - ETA: 2:12 - loss: 0.7078"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 101\u001b[0m\n\u001b[0;32m     93\u001b[0m model \u001b[38;5;241m=\u001b[39m build_model()\n\u001b[0;32m     95\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     96\u001b[0m                                mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     97\u001b[0m                                patience\u001b[38;5;241m=\u001b[39mPATIENCE,\n\u001b[0;32m     98\u001b[0m                                restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     99\u001b[0m                                verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 101\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBATCH_SIZE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(valid_dataset)\n\u001b[0;32m    110\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39minverse_transform(y_pred)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dropout, LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import itertools\n",
    "\n",
    "SEED = 42\n",
    "N_LAGS = 55\n",
    "BUFFER_SIZE = 100000\n",
    "SPLIT_DAY = 390\n",
    "N_STOCKS = 200\n",
    "N_SECONDS = 55\n",
    "RUN_TRAINING = True\n",
    "PATIENCE = 25\n",
    "EPOCHS = 10\n",
    "\n",
    "# Hyperparameters\n",
    "param_grid = {\n",
    "    'N_LAGS': [55, 60, 65],\n",
    "    'BATCH_SIZE': [32, 64],\n",
    "    'DROPOUT': [0.3, 0.5, 0.7],\n",
    "    'LEARNING_RATE': [1e-4, 1e-3],\n",
    "    'LSTM_UNITS': [25, 50]\n",
    "}\n",
    "\n",
    "best_mae = float('inf')\n",
    "best_hyperparameters = None\n",
    "\n",
    "def windowed_dataset(dataset, shuffle=True, batch_size=BATCH_SIZE):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(dataset)\n",
    "    dataset = dataset.window(N_LAGS + 1, shift=1, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(N_LAGS + 1))\n",
    "    dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "    dataset = dataset.batch(batch_size).prefetch(1)\n",
    "    return dataset\n",
    "\n",
    "def build_features(df):\n",
    "    all_stock_ids = range(N_STOCKS)\n",
    "    all_date_ids = df[\"date_id\"].unique()\n",
    "    all_seconds = [i * 10 for i in range(N_SECONDS)]\n",
    "\n",
    "    multi_index = pd.MultiIndex.from_product([all_stock_ids, all_date_ids, all_seconds],\n",
    "                                             names=['stock_id', 'date_id', 'seconds_in_bucket'])\n",
    "    df_full = df.set_index(['stock_id', 'date_id', 'seconds_in_bucket']).reindex(multi_index)\n",
    "    df_full = df_full.fillna(0)\n",
    "    df_full = df_full.reset_index()\n",
    "\n",
    "    df_pivoted = df_full.pivot_table(\n",
    "        values='target',\n",
    "        index=['date_id', 'seconds_in_bucket'],\n",
    "        columns='stock_id')\n",
    "\n",
    "    df_pivoted = df_pivoted.reset_index(drop=True)\n",
    "    df_pivoted.columns.name = None\n",
    "\n",
    "    return df_pivoted\n",
    "\n",
    "if RUN_TRAINING:\n",
    "    split = df_train['date_id'] > SPLIT_DAY\n",
    "    df_train_ = df_train[~split]\n",
    "    df_valid = df_train[split]\n",
    "\n",
    "    df_train_features = build_features(df_train_)\n",
    "    df_valid_features = build_features(df_valid)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    train_features = scaler.fit_transform(df_train_features)\n",
    "    valid_features = scaler.transform(df_valid_features)\n",
    "\n",
    "    train_dataset = windowed_dataset(train_features)\n",
    "    valid_dataset = windowed_dataset(valid_features, shuffle=False)\n",
    "\n",
    "    for params in itertools.product(*param_grid.values()):\n",
    "        hyperparameters = dict(zip(param_grid.keys(), params))\n",
    "\n",
    "        def build_model(dropout=hyperparameters['DROPOUT'], lstm_units=hyperparameters['LSTM_UNITS']):\n",
    "            model = Sequential()\n",
    "            model.add(Input(shape=(hyperparameters['N_LAGS'], N_STOCKS)))\n",
    "            model.add(Dropout(dropout))\n",
    "            model.add(LSTM(lstm_units, return_sequences=False))\n",
    "            model.add(Dropout(dropout))\n",
    "            model.add(Dense(N_STOCKS))\n",
    "            model.compile(loss='mae',\n",
    "                          optimizer=tf.keras.optimizers.Adam(learning_rate=hyperparameters['LEARNING_RATE']))\n",
    "            return model\n",
    "\n",
    "        model = build_model()\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                                       mode='min',\n",
    "                                       patience=PATIENCE,\n",
    "                                       restore_best_weights=True,\n",
    "                                       verbose=True)\n",
    "\n",
    "        history = model.fit(train_dataset,\n",
    "                            validation_data=valid_dataset,\n",
    "                            epochs=EPOCHS,\n",
    "                            batch_size=hyperparameters['BATCH_SIZE'],\n",
    "                            callbacks=[early_stopping],\n",
    "                            verbose=True)\n",
    "\n",
    "        y_pred = model.predict(valid_dataset)\n",
    "\n",
    "        y_pred = scaler.inverse_transform(y_pred)\n",
    "        y_true = df_valid_features[N_LAGS:]\n",
    "\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        print(f\"MAE score for hyperparameters {hyperparameters}: {mae}\")\n",
    "\n",
    "        if mae < best_mae:\n",
    "            best_mae = mae\n",
    "            best_hyperparameters = hyperparameters\n",
    "\n",
    "    print(f\"Best hyperparameters: {best_hyperparameters}, Best MAE: {best_mae}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Training parameters\n",
    "Epoch 1/10\n",
    "671/671 [==============================] - 50s 69ms/step - loss: 0.7005 - val_loss: 0.6466\n",
    "Epoch 2/10\n",
    "671/671 [==============================] - 39s 55ms/step - loss: 0.6756 - val_loss: 0.6352\n",
    "Epoch 3/10\n",
    "671/671 [==============================] - 51s 73ms/step - loss: 0.6691 - val_loss: 0.6302\n",
    "Epoch 4/10\n",
    "671/671 [==============================] - 65s 93ms/step - loss: 0.6661 - val_loss: 0.6276\n",
    "Epoch 5/10\n",
    "671/671 [==============================] - 43s 60ms/step - loss: 0.6641 - val_loss: 0.6256\n",
    "Epoch 6/10\n",
    "671/671 [==============================] - 35s 49ms/step - loss: 0.6626 - val_loss: 0.6250\n",
    "Epoch 7/10\n",
    "671/671 [==============================] - 40s 57ms/step - loss: 0.6613 - val_loss: 0.6241\n",
    "Epoch 8/10\n",
    "671/671 [==============================] - 39s 55ms/step - loss: 0.6605 - val_loss: 0.6231\n",
    "Epoch 9/10\n",
    "671/671 [==============================] - 48s 68ms/step - loss: 0.6598 - val_loss: 0.6229\n",
    "Epoch 10/10\n",
    "671/671 [==============================] - 36s 50ms/step - loss: 0.6594 - val_loss: 0.6221\n",
    "153/153 [==============================] - 2s 8ms/step\n",
    "MAE score for hyperparameters {'N_LAGS': 60, 'BATCH_SIZE': 32, 'DROPOUT': 0.3, 'LEARNING_RATE': 0.001, 'LSTM_UNITS': 50}: 5.548815727233887\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "N_LAGS = 60\n",
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 100000\n",
    "EPOCHS = 10\n",
    "PATIENCE = 25\n",
    "DROPOUT = 0.3\n",
    "LEARNING_RATE = 1e-3\n",
    "SPLIT_DAY = 390\n",
    "N_STOCKS = 200\n",
    "N_DATES = 481\n",
    "N_SECONDS = 55\n",
    "RUN_TRAINING = True\n",
    "# RUN_FOR_SUBMISSION = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.029704</td>\n",
       "      <td>-5.519986</td>\n",
       "      <td>-8.389950</td>\n",
       "      <td>-4.010201</td>\n",
       "      <td>-7.349849</td>\n",
       "      <td>6.779432</td>\n",
       "      <td>-2.499819</td>\n",
       "      <td>-1.959801</td>\n",
       "      <td>-5.970001</td>\n",
       "      <td>7.970333</td>\n",
       "      <td>...</td>\n",
       "      <td>6.370544</td>\n",
       "      <td>11.940002</td>\n",
       "      <td>-11.529922</td>\n",
       "      <td>-6.489754</td>\n",
       "      <td>3.999472</td>\n",
       "      <td>-0.690222</td>\n",
       "      <td>-0.810027</td>\n",
       "      <td>-8.440018</td>\n",
       "      <td>-0.510216</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.389814</td>\n",
       "      <td>-1.620054</td>\n",
       "      <td>-7.460117</td>\n",
       "      <td>-1.040101</td>\n",
       "      <td>-6.719828</td>\n",
       "      <td>7.710457</td>\n",
       "      <td>-4.280210</td>\n",
       "      <td>-8.010268</td>\n",
       "      <td>-0.780225</td>\n",
       "      <td>-0.640154</td>\n",
       "      <td>...</td>\n",
       "      <td>4.210472</td>\n",
       "      <td>2.599955</td>\n",
       "      <td>-15.599728</td>\n",
       "      <td>-1.749992</td>\n",
       "      <td>-9.030104</td>\n",
       "      <td>-1.320243</td>\n",
       "      <td>-3.259778</td>\n",
       "      <td>-4.410148</td>\n",
       "      <td>-1.419783</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.220009</td>\n",
       "      <td>-6.459951</td>\n",
       "      <td>-6.380081</td>\n",
       "      <td>-2.030134</td>\n",
       "      <td>-0.690222</td>\n",
       "      <td>1.009703</td>\n",
       "      <td>2.930164</td>\n",
       "      <td>-12.069941</td>\n",
       "      <td>-4.119873</td>\n",
       "      <td>-3.250241</td>\n",
       "      <td>...</td>\n",
       "      <td>5.379915</td>\n",
       "      <td>-5.970001</td>\n",
       "      <td>-12.710094</td>\n",
       "      <td>2.160072</td>\n",
       "      <td>-9.999871</td>\n",
       "      <td>5.890131</td>\n",
       "      <td>-0.029802</td>\n",
       "      <td>-6.819963</td>\n",
       "      <td>2.599955</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.450249</td>\n",
       "      <td>-5.149841</td>\n",
       "      <td>-5.819798</td>\n",
       "      <td>1.130104</td>\n",
       "      <td>-2.589822</td>\n",
       "      <td>-3.089905</td>\n",
       "      <td>0.560284</td>\n",
       "      <td>-6.909966</td>\n",
       "      <td>-1.090169</td>\n",
       "      <td>-6.759763</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.269911</td>\n",
       "      <td>1.300573</td>\n",
       "      <td>-16.660095</td>\n",
       "      <td>4.090071</td>\n",
       "      <td>-9.340048</td>\n",
       "      <td>7.020235</td>\n",
       "      <td>1.549721</td>\n",
       "      <td>1.690388</td>\n",
       "      <td>3.010035</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.169775</td>\n",
       "      <td>-6.750226</td>\n",
       "      <td>-0.280142</td>\n",
       "      <td>-2.350211</td>\n",
       "      <td>-4.900098</td>\n",
       "      <td>-2.070069</td>\n",
       "      <td>2.199411</td>\n",
       "      <td>-1.209974</td>\n",
       "      <td>-3.100038</td>\n",
       "      <td>-8.199811</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.009869</td>\n",
       "      <td>-0.969768</td>\n",
       "      <td>-9.229779</td>\n",
       "      <td>5.700588</td>\n",
       "      <td>-11.489987</td>\n",
       "      <td>4.500151</td>\n",
       "      <td>-1.350045</td>\n",
       "      <td>-1.929998</td>\n",
       "      <td>4.669428</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26450</th>\n",
       "      <td>3.999472</td>\n",
       "      <td>2.850294</td>\n",
       "      <td>-4.450083</td>\n",
       "      <td>1.720190</td>\n",
       "      <td>1.939535</td>\n",
       "      <td>-4.569888</td>\n",
       "      <td>-0.630021</td>\n",
       "      <td>-1.729727</td>\n",
       "      <td>-0.680089</td>\n",
       "      <td>3.540516</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.730225</td>\n",
       "      <td>-7.420182</td>\n",
       "      <td>2.959967</td>\n",
       "      <td>-2.359748</td>\n",
       "      <td>-0.650287</td>\n",
       "      <td>3.190041</td>\n",
       "      <td>-1.659989</td>\n",
       "      <td>-0.690222</td>\n",
       "      <td>-2.700090</td>\n",
       "      <td>-7.209778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26451</th>\n",
       "      <td>3.190041</td>\n",
       "      <td>3.169775</td>\n",
       "      <td>-5.559921</td>\n",
       "      <td>4.669428</td>\n",
       "      <td>2.139807</td>\n",
       "      <td>1.679659</td>\n",
       "      <td>-0.360012</td>\n",
       "      <td>-3.240108</td>\n",
       "      <td>2.609491</td>\n",
       "      <td>1.679659</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.340244</td>\n",
       "      <td>-3.479719</td>\n",
       "      <td>1.419783</td>\n",
       "      <td>-1.069903</td>\n",
       "      <td>2.319813</td>\n",
       "      <td>3.770590</td>\n",
       "      <td>-3.039837</td>\n",
       "      <td>-3.299713</td>\n",
       "      <td>-2.070069</td>\n",
       "      <td>-9.750128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26452</th>\n",
       "      <td>-0.169873</td>\n",
       "      <td>5.689859</td>\n",
       "      <td>-5.310178</td>\n",
       "      <td>5.639791</td>\n",
       "      <td>1.660585</td>\n",
       "      <td>2.110004</td>\n",
       "      <td>-1.000166</td>\n",
       "      <td>-4.529953</td>\n",
       "      <td>5.409718</td>\n",
       "      <td>0.350475</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.549721</td>\n",
       "      <td>-1.289845</td>\n",
       "      <td>-0.140071</td>\n",
       "      <td>-1.929998</td>\n",
       "      <td>4.609823</td>\n",
       "      <td>1.449585</td>\n",
       "      <td>-6.319880</td>\n",
       "      <td>-1.999736</td>\n",
       "      <td>-2.239943</td>\n",
       "      <td>3.629923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26453</th>\n",
       "      <td>3.110170</td>\n",
       "      <td>10.650158</td>\n",
       "      <td>-5.239844</td>\n",
       "      <td>5.229712</td>\n",
       "      <td>0.300407</td>\n",
       "      <td>-2.030134</td>\n",
       "      <td>-1.180172</td>\n",
       "      <td>-1.310110</td>\n",
       "      <td>3.240108</td>\n",
       "      <td>0.220537</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.440048</td>\n",
       "      <td>-0.299811</td>\n",
       "      <td>-2.120137</td>\n",
       "      <td>-1.350045</td>\n",
       "      <td>3.110170</td>\n",
       "      <td>4.019737</td>\n",
       "      <td>-7.349849</td>\n",
       "      <td>-3.259778</td>\n",
       "      <td>-3.160238</td>\n",
       "      <td>4.760027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26454</th>\n",
       "      <td>0.760555</td>\n",
       "      <td>15.859604</td>\n",
       "      <td>-1.549721</td>\n",
       "      <td>3.160238</td>\n",
       "      <td>1.009703</td>\n",
       "      <td>2.340078</td>\n",
       "      <td>1.410246</td>\n",
       "      <td>-1.260042</td>\n",
       "      <td>3.679991</td>\n",
       "      <td>-1.609921</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.470281</td>\n",
       "      <td>0.799894</td>\n",
       "      <td>-1.729727</td>\n",
       "      <td>-3.880262</td>\n",
       "      <td>4.839897</td>\n",
       "      <td>2.310276</td>\n",
       "      <td>-8.220077</td>\n",
       "      <td>1.169443</td>\n",
       "      <td>-1.540184</td>\n",
       "      <td>-6.530285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26455 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1         2         3         4         5         6    \\\n",
       "0     -3.029704  -5.519986 -8.389950 -4.010201 -7.349849  6.779432 -2.499819   \n",
       "1      0.389814  -1.620054 -7.460117 -1.040101 -6.719828  7.710457 -4.280210   \n",
       "2      4.220009  -6.459951 -6.380081 -2.030134 -0.690222  1.009703  2.930164   \n",
       "3      5.450249  -5.149841 -5.819798  1.130104 -2.589822 -3.089905  0.560284   \n",
       "4      3.169775  -6.750226 -0.280142 -2.350211 -4.900098 -2.070069  2.199411   \n",
       "...         ...        ...       ...       ...       ...       ...       ...   \n",
       "26450  3.999472   2.850294 -4.450083  1.720190  1.939535 -4.569888 -0.630021   \n",
       "26451  3.190041   3.169775 -5.559921  4.669428  2.139807  1.679659 -0.360012   \n",
       "26452 -0.169873   5.689859 -5.310178  5.639791  1.660585  2.110004 -1.000166   \n",
       "26453  3.110170  10.650158 -5.239844  5.229712  0.300407 -2.030134 -1.180172   \n",
       "26454  0.760555  15.859604 -1.549721  3.160238  1.009703  2.340078  1.410246   \n",
       "\n",
       "             7         8         9    ...       190        191        192  \\\n",
       "0      -1.959801 -5.970001  7.970333  ...  6.370544  11.940002 -11.529922   \n",
       "1      -8.010268 -0.780225 -0.640154  ...  4.210472   2.599955 -15.599728   \n",
       "2     -12.069941 -4.119873 -3.250241  ...  5.379915  -5.970001 -12.710094   \n",
       "3      -6.909966 -1.090169 -6.759763  ... -3.269911   1.300573 -16.660095   \n",
       "4      -1.209974 -3.100038 -8.199811  ... -2.009869  -0.969768  -9.229779   \n",
       "...          ...       ...       ...  ...       ...        ...        ...   \n",
       "26450  -1.729727 -0.680089  3.540516  ... -4.730225  -7.420182   2.959967   \n",
       "26451  -3.240108  2.609491  1.679659  ... -3.340244  -3.479719   1.419783   \n",
       "26452  -4.529953  5.409718  0.350475  ... -1.549721  -1.289845  -0.140071   \n",
       "26453  -1.310110  3.240108  0.220537  ... -1.440048  -0.299811  -2.120137   \n",
       "26454  -1.260042  3.679991 -1.609921  ... -0.470281   0.799894  -1.729727   \n",
       "\n",
       "            193        194       195       196       197       198       199  \n",
       "0     -6.489754   3.999472 -0.690222 -0.810027 -8.440018 -0.510216  0.000000  \n",
       "1     -1.749992  -9.030104 -1.320243 -3.259778 -4.410148 -1.419783  0.000000  \n",
       "2      2.160072  -9.999871  5.890131 -0.029802 -6.819963  2.599955  0.000000  \n",
       "3      4.090071  -9.340048  7.020235  1.549721  1.690388  3.010035  0.000000  \n",
       "4      5.700588 -11.489987  4.500151 -1.350045 -1.929998  4.669428  0.000000  \n",
       "...         ...        ...       ...       ...       ...       ...       ...  \n",
       "26450 -2.359748  -0.650287  3.190041 -1.659989 -0.690222 -2.700090 -7.209778  \n",
       "26451 -1.069903   2.319813  3.770590 -3.039837 -3.299713 -2.070069 -9.750128  \n",
       "26452 -1.929998   4.609823  1.449585 -6.319880 -1.999736 -2.239943  3.629923  \n",
       "26453 -1.350045   3.110170  4.019737 -7.349849 -3.259778 -3.160238  4.760027  \n",
       "26454 -3.880262   4.839897  2.310276 -8.220077  1.169443 -1.540184 -6.530285  \n",
       "\n",
       "[26455 rows x 200 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_features(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "671/671 [==============================] - 87s 103ms/step - loss: 0.7065 - val_loss: 0.6570\n",
      "Epoch 2/10\n",
      "671/671 [==============================] - 67s 87ms/step - loss: 0.6877 - val_loss: 0.6497\n",
      "Epoch 3/10\n",
      "671/671 [==============================] - 67s 86ms/step - loss: 0.6833 - val_loss: 0.6469\n",
      "Epoch 4/10\n",
      "671/671 [==============================] - 68s 86ms/step - loss: 0.6807 - val_loss: 0.6447\n",
      "Epoch 5/10\n",
      "671/671 [==============================] - 68s 87ms/step - loss: 0.6792 - val_loss: 0.6437\n",
      "Epoch 6/10\n",
      "671/671 [==============================] - 68s 86ms/step - loss: 0.6779 - val_loss: 0.6425\n",
      "Epoch 7/10\n",
      "671/671 [==============================] - 68s 87ms/step - loss: 0.6771 - val_loss: 0.6417\n",
      "Epoch 8/10\n",
      "671/671 [==============================] - 67s 85ms/step - loss: 0.6761 - val_loss: 0.6410\n",
      "Epoch 9/10\n",
      "671/671 [==============================] - 68s 87ms/step - loss: 0.6753 - val_loss: 0.6402\n",
      "Epoch 10/10\n",
      "671/671 [==============================] - 68s 85ms/step - loss: 0.6746 - val_loss: 0.6400\n",
      "153/153 [==============================] - 4s 23ms/step\n",
      "MAE score: 5.703173637390137\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dropout, LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import itertools\n",
    "\n",
    "SEED = 42\n",
    "N_LAGS = 60\n",
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 100000\n",
    "EPOCHS = 25\n",
    "PATIENCE = 25\n",
    "DROPOUT = 0.3\n",
    "LEARNING_RATE = 1e-3\n",
    "SPLIT_DAY = 390\n",
    "N_STOCKS = 200\n",
    "N_DATES = 481\n",
    "N_SECONDS = 55\n",
    "RUN_TRAINING = True\n",
    "\n",
    "\n",
    "best_mae = float('inf')\n",
    "best_hyperparameters = None\n",
    "\n",
    "def windowed_dataset(dataset, shuffle=True, batch_size=BATCH_SIZE):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(dataset)\n",
    "    dataset = dataset.window(N_LAGS + 1, shift=1, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(N_LAGS + 1))\n",
    "    dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "    dataset = dataset.batch(batch_size).prefetch(1)\n",
    "    return dataset\n",
    "\n",
    "def build_features(df):\n",
    "    all_stock_ids = range(N_STOCKS)\n",
    "    all_date_ids = df[\"date_id\"].unique()\n",
    "    all_seconds = [i * 10 for i in range(N_SECONDS)]\n",
    "\n",
    "    multi_index = pd.MultiIndex.from_product([all_stock_ids, all_date_ids, all_seconds],\n",
    "                                             names=['stock_id', 'date_id', 'seconds_in_bucket'])\n",
    "    df_full = df.set_index(['stock_id', 'date_id', 'seconds_in_bucket']).reindex(multi_index)\n",
    "    df_full = df_full.fillna(0)\n",
    "    df_full = df_full.reset_index()\n",
    "\n",
    "    df_pivoted = df_full.pivot_table(\n",
    "        values='target',\n",
    "        index=['date_id', 'seconds_in_bucket'],\n",
    "        columns='stock_id')\n",
    "\n",
    "    df_pivoted = df_pivoted.reset_index(drop=True)\n",
    "    df_pivoted.columns.name = None\n",
    "\n",
    "    return df_pivoted\n",
    "\n",
    "if RUN_TRAINING:\n",
    "\n",
    "  split = df_train['date_id'] > SPLIT_DAY\n",
    "  df_train_ = df_train[~split]\n",
    "  df_valid = df_train[split]\n",
    "\n",
    "  df_train_features = build_features(df_train_)\n",
    "  df_valid_features = build_features(df_valid)\n",
    "\n",
    "  scaler = StandardScaler()\n",
    "  train_features = scaler.fit_transform(df_train_features)\n",
    "  valid_features = scaler.transform(df_valid_features)\n",
    "\n",
    "  train_dataset = windowed_dataset(train_features)\n",
    "  valid_dataset = windowed_dataset(valid_features, shuffle=False)\n",
    "\n",
    "  model = build_model()\n",
    "\n",
    "  early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                    mode='min',\n",
    "                    patience=PATIENCE,\n",
    "                    restore_best_weights=True,\n",
    "                    verbose=True)\n",
    "\n",
    "  history = model.fit(train_dataset,\n",
    "                      validation_data=valid_dataset,\n",
    "                      epochs=EPOCHS,\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      callbacks=[early_stopping],\n",
    "                      verbose=True)\n",
    "\n",
    "  ## Evaluate ##\n",
    "  y_pred = model.predict(valid_dataset)\n",
    "\n",
    "  y_pred = scaler.inverse_transform(y_pred)\n",
    "  y_true = df_valid_features[N_LAGS:]\n",
    "\n",
    "  mae = mean_absolute_error(y_true, y_pred)\n",
    "  print(f\"MAE score: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plots ##\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model train vs validation loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
